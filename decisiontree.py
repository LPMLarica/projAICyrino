# Atividade Pr√°tica: Classifica√ß√£o Supervisionada
# Algoritmos: √Årvore de Decis√£o e KNN
# Autor: Larissa Campos Cardoso
# Data: 28/10/2025

# Imports

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_iris, load_wine
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import (
    confusion_matrix, 
    classification_report, 
    accuracy_score,
    precision_score, 
    recall_score, 
    f1_score
)
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Config Visual
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("=" * 80)
print("ATIVIDADE PR√ÅTICA: CLASSIFICA√á√ÉO SUPERVISIONADA")
print("Algoritmos: √Årvore de Decis√£o e KNN")
print("=" * 80)

# Carregamento dados e prepara√ß√£o

print("\n" + "=" * 80)
print("2. CARREGAMENTO E EXPLORA√á√ÉO DOS DADOS")
print("=" * 80)

iris = load_iris()
X_iris = iris.data
y_iris = iris.target

df_iris = pd.DataFrame(X_iris, columns=iris.feature_names)
df_iris['target'] = y_iris
df_iris['species'] = df_iris['target'].map({
    0: iris.target_names[0],
    1: iris.target_names[1],
    2: iris.target_names[2]
})

print("\n Dataset: IRIS")
print(f"   Dimens√µes: {X_iris.shape}")
print(f"   Classes: {iris.target_names}")
print(f"   Features: {iris.feature_names}")
print("\nPrimeiras linhas:")
print(df_iris.head())

print("\n Distribui√ß√£o das classes:")
print(df_iris['species'].value_counts())

print("\n Estat√≠sticas descritivas:")
print(df_iris.describe())

# Divis√£o de dados

print("\n" + "=" * 80)
print("3. DIVIS√ÉO DOS DADOS")
print("=" * 80)

# treino (70%), teste (30%)

X_train, X_test, y_train, y_test = train_test_split(
    X_iris, y_iris, 
    test_size=0.3, 
    random_state=42, 
    stratify=y_iris
)

print(f"\n‚úì Conjunto de treino: {X_train.shape[0]} amostras")
print(f"‚úì Conjunto de teste: {X_test.shape[0]} amostras")
print(f"‚úì Propor√ß√£o: 70% treino / 30% teste")

# Normaliza√ß√£o
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("‚úì Dados normalizados (StandardScaler)")

# MODELO 1: √ÅRVORE DE DECIS√ÉO

print("\n" + "=" * 80)
print("4. MODELO 1: √ÅRVORE DE DECIS√ÉO")
print("=" * 80)

dt_model = DecisionTreeClassifier(
    max_depth=4, 
    random_state=42,
    criterion='gini'
)
dt_model.fit(X_train, y_train)

print("\n‚úì Modelo treinado com sucesso!")
print(f"  Profundidade da √°rvore: {dt_model.get_depth()}")
print(f"  N√∫mero de folhas: {dt_model.get_n_leaves()}")

# Predi√ß√µes
y_pred_dt = dt_model.predict(X_test)

# M√©tricas
dt_accuracy = accuracy_score(y_test, y_pred_dt)
dt_precision = precision_score(y_test, y_pred_dt, average='weighted')
dt_recall = recall_score(y_test, y_pred_dt, average='weighted')
dt_f1 = f1_score(y_test, y_pred_dt, average='weighted')

print("\n M√âTRICAS - √ÅRVORE DE DECIS√ÉO:")
print(f"   Acur√°cia:  {dt_accuracy:.4f} ({dt_accuracy*100:.2f}%)")
print(f"   Precis√£o:  {dt_precision:.4f}")
print(f"   Recall:    {dt_recall:.4f}")
print(f"   F1-Score:  {dt_f1:.4f}")

# Matriz de Confus√£o
cm_dt = confusion_matrix(y_test, y_pred_dt)
print("\n Matriz de Confus√£o:")
print(cm_dt)

# Relat√≥rio 
print("\n Relat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred_dt, target_names=iris.target_names))

# MODELO 2: KNN 

print("\n" + "=" * 80)
print("5. MODELO 2: KNN (K-NEAREST NEIGHBORS)")
print("=" * 80)

# k=5
knn_model = KNeighborsClassifier(n_neighbors=5, metric='euclidean')
knn_model.fit(X_train_scaled, y_train)

print("\n‚úì Modelo KNN treinado com sucesso!")
print(f"  N√∫mero de vizinhos (k): {knn_model.n_neighbors}")
print(f"  M√©trica de dist√¢ncia: {knn_model.metric}")

# Predi√ß√µes
y_pred_knn = knn_model.predict(X_test_scaled)

# M√©tricas
knn_accuracy = accuracy_score(y_test, y_pred_knn)
knn_precision = precision_score(y_test, y_pred_knn, average='weighted')
knn_recall = recall_score(y_test, y_pred_knn, average='weighted')
knn_f1 = f1_score(y_test, y_pred_knn, average='weighted')

print("\n M√âTRICAS - KNN:")
print(f"   Acur√°cia:  {knn_accuracy:.4f} ({knn_accuracy*100:.2f}%)")
print(f"   Precis√£o:  {knn_precision:.4f}")
print(f"   Recall:    {knn_recall:.4f}")
print(f"   F1-Score:  {knn_f1:.4f}")

# Matriz de Confus√£o
cm_knn = confusion_matrix(y_test, y_pred_knn)
print("\nüìã Matriz de Confus√£o:")
print(cm_knn)

# Relat√≥rio
print("\n Relat√≥rio de Classifica√ß√£o:")
print(classification_report(y_test, y_pred_knn, target_names=iris.target_names))

# Visualizar

print("\n" + "=" * 80)
print("6. VISUALIZA√á√ïES")
print("=" * 80)

# Cria figura 
fig = plt.figure(figsize=(16, 10))

# Matriz de Confus√£o - √Årvore de Decis√£o
plt.subplot(2, 3, 1)
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', 
            xticklabels=iris.target_names,
            yticklabels=iris.target_names)
plt.title('Matriz de Confus√£o\n√Årvore de Decis√£o', fontsize=12, fontweight='bold')
plt.ylabel('Classe Real')
plt.xlabel('Classe Predita')

# Matriz de Confus√£o - KNN
plt.subplot(2, 3, 2)
sns.heatmap(cm_knn, annot=True, fmt='d', cmap='Greens',
            xticklabels=iris.target_names,
            yticklabels=iris.target_names)
plt.title('Matriz de Confus√£o\nKNN', fontsize=12, fontweight='bold')
plt.ylabel('Classe Real')
plt.xlabel('Classe Predita')

# Compara√ß√£o de M√©tricas
plt.subplot(2, 3, 3)
metrics = ['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score']
dt_scores = [dt_accuracy, dt_precision, dt_recall, dt_f1]
knn_scores = [knn_accuracy, knn_precision, knn_recall, knn_f1]

x = np.arange(len(metrics))
width = 0.35

bars1 = plt.bar(x - width/2, dt_scores, width, label='√Årvore de Decis√£o', color='#3498db')
bars2 = plt.bar(x + width/2, knn_scores, width, label='KNN', color='#2ecc71')

plt.ylabel('Score')
plt.title('Compara√ß√£o de M√©tricas', fontsize=12, fontweight='bold')
plt.xticks(x, metrics, rotation=45)
plt.ylim([0.9, 1.01])
plt.legend()
plt.grid(axis='y', alpha=0.3)

for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontsize=8)

plt.subplot(2, 3, (4, 6))
plot_tree(dt_model, 
          feature_names=iris.feature_names,
          class_names=iris.target_names,
          filled=True,
          rounded=True,
          fontsize=8)
plt.title('Estrutura da √Årvore de Decis√£o', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('comparacao_modelos.png', dpi=300, bbox_inches='tight')
print("\n‚úì Gr√°ficos gerados e salvos como 'comparacao_modelos.png'")
plt.show()

# 7. An√°lise KNN

print("\n" + "=" * 80)
print("7. AN√ÅLISE DE DIFERENTES VALORES DE K")
print("=" * 80)

k_values = range(1, 21)
k_scores = []

for k in k_values:
    knn_temp = KNeighborsClassifier(n_neighbors=k)
    knn_temp.fit(X_train_scaled, y_train)
    score = knn_temp.score(X_test_scaled, y_test)
    k_scores.append(score)

# Plotar
plt.figure(figsize=(10, 6))
plt.plot(k_values, k_scores, marker='o', linestyle='-', linewidth=2, markersize=8)
plt.xlabel('N√∫mero de Vizinhos (k)', fontsize=12)
plt.ylabel('Acur√°cia', fontsize=12)
plt.title('Acur√°cia do KNN vs Valor de K', fontsize=14, fontweight='bold')
plt.grid(True, alpha=0.3)
plt.xticks(k_values)

# Marcar o melhor k
best_k = k_values[np.argmax(k_scores)]
best_score = max(k_scores)
plt.axvline(x=best_k, color='red', linestyle='--', alpha=0.7, label=f'Melhor k={best_k}')
plt.legend()

plt.tight_layout()
plt.savefig('knn_k_analysis.png', dpi=300, bbox_inches='tight')
print(f"\n‚úì Melhor valor de k: {best_k} (Acur√°cia: {best_score:.4f})")
plt.show()

# An√°lise final

print("\n" + "=" * 80)
print("8. AN√ÅLISE COMPARATIVA FINAL")
print("=" * 80)

print("\n" + "="*80)
print("RESUMO COMPARATIVO DOS MODELOS")
print("="*80)

comparison_df = pd.DataFrame({
    'M√©trica': ['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score'],
    '√Årvore de Decis√£o': [dt_accuracy, dt_precision, dt_recall, dt_f1],
    'KNN (k=5)': [knn_accuracy, knn_precision, knn_recall, knn_f1]
})

print("\n", comparison_df.to_string(index=False))

# melhor modelo
if dt_f1 > knn_f1:
    melhor = "√Årvore de Decis√£o"
    diferenca = dt_f1 - knn_f1
else:
    melhor = "KNN"
    diferenca = knn_f1 - dt_f1

print(f"\nüèÜ MELHOR MODELO: {melhor}")
print(f"   Diferen√ßa de F1-Score: {diferenca:.4f}")

# Concluindo

print("\n" + "=" * 80)
print("9. CONCLUS√ïES E INTERPRETA√á√ïES")
print("=" * 80)

print("""
 AN√ÅLISE FINAL:

1. DESEMPENHO GERAL:
   Ambos os modelos apresentaram excelente desempenho no dataset Iris,
   com acur√°cias superiores a 95%. Isso se deve √† natureza bem separ√°vel
   das classes neste dataset cl√°ssico.

2. √ÅRVORE DE DECIS√ÉO:
   ‚úì Vantagens:
     - Interpret√°vel e visual (podemos ver a l√≥gica de decis√£o)
     - N√£o requer normaliza√ß√£o dos dados
     - R√°pida para fazer predi√ß√µes
     - Captura rela√ß√µes n√£o-lineares facilmente
   
   ‚úó Desvantagens:
     - Pode sofrer overfitting com √°rvores muito profundas
     - Sens√≠vel a pequenas varia√ß√µes nos dados de treino
     - Pode criar regi√µes de decis√£o muito complexas

3. KNN (K-NEAREST NEIGHBORS):
   ‚úì Vantagens:
     - Simples e intuitivo
     - N√£o faz suposi√ß√µes sobre distribui√ß√£o dos dados
     - Adapta-se bem a fronteiras de decis√£o irregulares
     - Performance ajust√°vel pelo par√¢metro k
   
   ‚úó Desvantagens:
     - Computacionalmente custoso em grandes datasets
     - Sens√≠vel √† escala das features (requer normaliza√ß√£o)
     - Performance depende da escolha de k
     - Armazena todo o conjunto de treino

4. INTERPRETA√á√ÉO DAS MATRIZES DE CONFUS√ÉO:
   As matrizes mostram que ambos os modelos tiveram poucos erros de
   classifica√ß√£o. A maioria dos erros ocorreu na distin√ß√£o entre as
   esp√©cies versicolor e virginica, que s√£o naturalmente mais similares.

5. ESCOLHA DO MODELO:
   - Para INTERPRETABILIDADE: √Årvore de Decis√£o
   - Para DATASETS PEQUENOS: KNN pode ser mais eficiente
   - Para PRODU√á√ÉO: Considerar ensemble (Random Forest) ou valida√ß√£o cruzada

6. M√âTRICAS UTILIZADAS:
   - ACUR√ÅCIA: Propor√ß√£o de predi√ß√µes corretas
   - PRECIS√ÉO: Propor√ß√£o de positivos preditos que s√£o realmente positivos
   - RECALL: Propor√ß√£o de positivos reais que foram identificados
   - F1-SCORE: M√©dia harm√¥nica entre precis√£o e recall (mais robusta)

7. PR√ìXIMOS PASSOS:
   - Testar em outros datasets (Wine, Breast Cancer)
   - Aplicar valida√ß√£o cruzada (cross-validation)
   - Ajustar hiperpar√¢metros (GridSearchCV)
   - Experimentar ensemble methods (Random Forest, Gradient Boosting)
   - Analisar curvas ROC e AUC para classifica√ß√£o multiclasse
""")

print("\n" + "=" * 80)
print("FIM DA AN√ÅLISE")
print("=" * 80)
print("\n‚úì Notebook executado com sucesso!")
print("‚úì Gr√°ficos salvos: 'comparacao_modelos.png' e 'knn_k_analysis.png'")
print("\n Refer√™ncias:")
print("   - Scikit-learn Documentation: https://scikit-learn.org")
print("   - UCI ML Repository: https://archive.ics.uci.edu/ml")
print("="*80)
